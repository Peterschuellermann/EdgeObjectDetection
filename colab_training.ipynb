{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train YOLOv8 on SpaceNet 6 (Rotterdam)\n",
        "\n",
        "This notebook automates the download, preparation, and training of a YOLOv8 model on the SpaceNet 6 Rotterdam aerial imagery dataset.\n",
        "\n",
        "**Runtime Requirement**: ensure you are connected to a GPU runtime (Runtime > Change runtime type > T4 GPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Install Dependencies\n",
        "!pip install ultralytics rasterio geopandas boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import boto3\n",
        "from botocore import UNSIGNED\n",
        "from botocore.config import Config\n",
        "import rasterio\n",
        "import geopandas as gpd\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "import shutil\n",
        "import random\n",
        "import yaml\n",
        "import numpy as np\n",
        "\n",
        "# 2. Configuration\n",
        "BUCKET = 'spacenet-dataset'\n",
        "PREFIX_IMAGES = 'spacenet/SN6_buildings/train/AOI_11_Rotterdam/PS-RGB/'\n",
        "PREFIX_LABELS = 'spacenet/SN6_buildings/train/AOI_11_Rotterdam/geojson_buildings/'\n",
        "LOCAL_DIR = '/content/dataset'\n",
        "IMAGE_DIR = os.path.join(LOCAL_DIR, 'images')\n",
        "GEOJSON_DIR = os.path.join(LOCAL_DIR, 'geojson')\n",
        "LABEL_DIR = os.path.join(LOCAL_DIR, 'labels')\n",
        "\n",
        "os.makedirs(IMAGE_DIR, exist_ok=True)\n",
        "os.makedirs(GEOJSON_DIR, exist_ok=True)\n",
        "os.makedirs(LABEL_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Download Data\n",
        "def download_s3_folder(bucket, prefix, local_dir):\n",
        "    s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
        "    paginator = s3.get_paginator('list_objects_v2')\n",
        "    print(f\"Downloading from {prefix}...\")\n",
        "    for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
        "        if 'Contents' in page:\n",
        "            for obj in page['Contents']:\n",
        "                key = obj['Key']\n",
        "                if key.endswith('/'): continue\n",
        "                filename = os.path.basename(key)\n",
        "                local_path = os.path.join(local_dir, filename)\n",
        "                if not os.path.exists(local_path):\n",
        "                    s3.download_file(bucket, key, local_path)\n",
        "\n",
        "download_s3_folder(BUCKET, PREFIX_LABELS, GEOJSON_DIR)\n",
        "download_s3_folder(BUCKET, PREFIX_IMAGES, IMAGE_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Convert Labels to YOLO Format\n",
        "def detect_black_bars(image_array, threshold=10, min_bar_size=5, bar_threshold=0.95):\n",
        "    \"\"\"\n",
        "    Detect black bars at the top and bottom of an image.\n",
        "    \n",
        "    Args:\n",
        "        image_array: numpy array of shape (H, W) or (H, W, C)\n",
        "        threshold: pixel value threshold below which is considered \"black\" (0-255)\n",
        "        min_bar_size: minimum number of rows/columns to consider as a bar\n",
        "        bar_threshold: fraction of pixels in a row/column that must be black to consider it a bar\n",
        "    \n",
        "    Returns:\n",
        "        tuple: (top_crop, bottom_crop, left_crop, right_crop) in pixels\n",
        "    \"\"\"\n",
        "    # Handle multi-channel images by converting to grayscale\n",
        "    if len(image_array.shape) == 3:\n",
        "        gray = np.mean(image_array, axis=2)\n",
        "    else:\n",
        "        gray = image_array\n",
        "    \n",
        "    height, width = gray.shape\n",
        "    top_crop = 0\n",
        "    bottom_crop = 0\n",
        "    left_crop = 0\n",
        "    right_crop = 0\n",
        "    \n",
        "    # Detect top black bar\n",
        "    for i in range(height):\n",
        "        row = gray[i, :]\n",
        "        black_pixels = np.sum(row < threshold)\n",
        "        if black_pixels / width >= bar_threshold:\n",
        "            top_crop = i + 1\n",
        "        else:\n",
        "            break\n",
        "    \n",
        "    # Detect bottom black bar\n",
        "    for i in range(height - 1, -1, -1):\n",
        "        row = gray[i, :]\n",
        "        black_pixels = np.sum(row < threshold)\n",
        "        if black_pixels / width >= bar_threshold:\n",
        "            bottom_crop = height - i\n",
        "        else:\n",
        "            break\n",
        "    \n",
        "    # Detect left black bar\n",
        "    for j in range(width):\n",
        "        col = gray[:, j]\n",
        "        black_pixels = np.sum(col < threshold)\n",
        "        if black_pixels / height >= bar_threshold:\n",
        "            left_crop = j + 1\n",
        "        else:\n",
        "            break\n",
        "    \n",
        "    # Detect right black bar\n",
        "    for j in range(width - 1, -1, -1):\n",
        "        col = gray[:, j]\n",
        "        black_pixels = np.sum(col < threshold)\n",
        "        if black_pixels / height >= bar_threshold:\n",
        "            right_crop = width - j\n",
        "        else:\n",
        "            break\n",
        "    \n",
        "    # Only return crops if they meet minimum size\n",
        "    if top_crop < min_bar_size:\n",
        "        top_crop = 0\n",
        "    if bottom_crop < min_bar_size:\n",
        "        bottom_crop = 0\n",
        "    if left_crop < min_bar_size:\n",
        "        left_crop = 0\n",
        "    if right_crop < min_bar_size:\n",
        "        right_crop = 0\n",
        "    \n",
        "    return top_crop, bottom_crop, left_crop, right_crop\n",
        "\n",
        "def convert_labels():\n",
        "    geojson_files = glob.glob(os.path.join(GEOJSON_DIR, \"*.geojson\"))\n",
        "    print(f\"Found {len(geojson_files)} label files.\")\n",
        "    \n",
        "    for geojson_path in tqdm(geojson_files, desc=\"Converting\"):\n",
        "        filename = os.path.basename(geojson_path)\n",
        "        # SN6_Train_AOI_11_Rotterdam_Buildings_... -> SN6_Train_AOI_11_Rotterdam_PS-RGB_...\n",
        "        image_filename = filename.replace(\"Buildings\", \"PS-RGB\").replace(\".geojson\", \".tif\")\n",
        "        image_path = os.path.join(IMAGE_DIR, image_filename)\n",
        "        \n",
        "        if not os.path.exists(image_path):\n",
        "            continue\n",
        "            \n",
        "        try:\n",
        "            with rasterio.open(image_path) as src:\n",
        "                img_height, img_width = src.height, src.width\n",
        "                src_transform = src.transform\n",
        "                src_crs = src.crs\n",
        "                \n",
        "                # Detect black bars\n",
        "                image_array = src.read()\n",
        "                # Convert from (C, H, W) to (H, W, C) for detection\n",
        "                if len(image_array.shape) == 3:\n",
        "                    image_array = np.transpose(image_array, (1, 2, 0))\n",
        "                \n",
        "                top_crop, bottom_crop, left_crop, right_crop = detect_black_bars(\n",
        "                    image_array, threshold=10, min_bar_size=5, bar_threshold=0.95\n",
        "                )\n",
        "                \n",
        "                # Adjust image dimensions for cropping\n",
        "                effective_height = img_height - top_crop - bottom_crop\n",
        "                effective_width = img_width - left_crop - right_crop\n",
        "                \n",
        "            gdf = gpd.read_file(geojson_path)\n",
        "            yolo_lines = []\n",
        "            \n",
        "            if not gdf.empty:\n",
        "                if src_crs and src_crs.to_string() != \"EPSG:4326\":\n",
        "                     try:\n",
        "                        gdf = gdf.to_crs(src_crs)\n",
        "                     except Exception:\n",
        "                        pass\n",
        "\n",
        "                for _, row in gdf.iterrows():\n",
        "                    geom = row.geometry\n",
        "                    if geom.is_empty:\n",
        "                        continue\n",
        "                    \n",
        "                    minx, miny, maxx, maxy = geom.bounds\n",
        "                    # ~src_transform * (x, y) returns (col, row) which is (x, y) in pixels.\n",
        "                    c1, r1 = ~src_transform * (minx, maxy)\n",
        "                    c2, r2 = ~src_transform * (maxx, miny)\n",
        "                    \n",
        "                    xmin_px = min(c1, c2)\n",
        "                    xmax_px = max(c1, c2)\n",
        "                    ymin_px = min(r1, r2)\n",
        "                    ymax_px = max(r1, r2)\n",
        "                    \n",
        "                    # Adjust for black bar cropping\n",
        "                    xmin_px = xmin_px - left_crop\n",
        "                    xmax_px = xmax_px - left_crop\n",
        "                    ymin_px = ymin_px - top_crop\n",
        "                    ymax_px = ymax_px - top_crop\n",
        "                    \n",
        "                    # Clip to cropped image bounds\n",
        "                    xmin_px = max(0, xmin_px)\n",
        "                    ymin_px = max(0, ymin_px)\n",
        "                    xmax_px = min(effective_width, xmax_px)\n",
        "                    ymax_px = min(effective_height, ymax_px)\n",
        "                    \n",
        "                    if xmax_px <= xmin_px or ymax_px <= ymin_px:\n",
        "                        continue\n",
        "                    \n",
        "                    # Convert to YOLO format (normalize by cropped image dimensions)\n",
        "                    bbox_width = xmax_px - xmin_px\n",
        "                    bbox_height = ymax_px - ymin_px\n",
        "                    x_center = xmin_px + bbox_width / 2\n",
        "                    y_center = ymin_px + bbox_height / 2\n",
        "                    \n",
        "                    x_center /= effective_width\n",
        "                    y_center /= effective_height\n",
        "                    bbox_width /= effective_width\n",
        "                    bbox_height /= effective_height\n",
        "                    \n",
        "                    yolo_lines.append(f\"0 {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\")\n",
        "            \n",
        "            with open(os.path.join(LABEL_DIR, image_filename.replace(\".tif\", \".txt\")), \"w\") as f:\n",
        "                f.write(\"\\n\".join(yolo_lines))\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "convert_labels()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Split Dataset and Config\n",
        "images = glob.glob(os.path.join(IMAGE_DIR, \"*.tif\"))\n",
        "random.shuffle(images)\n",
        "split = int(len(images) * 0.8)\n",
        "train_imgs = images[:split]\n",
        "val_imgs = images[split:]\n",
        "\n",
        "with open('train.txt', 'w') as f:\n",
        "    f.write('\\n'.join(train_imgs))\n",
        "\n",
        "with open('val.txt', 'w') as f:\n",
        "    f.write('\\n'.join(val_imgs))\n",
        "\n",
        "data_yaml = f\"\"\"\n",
        "names:\n",
        "  0: building\n",
        "path: {os.getcwd()}\n",
        "train: train.txt\n",
        "val: val.txt\n",
        "\"\"\"\n",
        "\n",
        "with open('data.yaml', 'w') as f:\n",
        "    f.write(data_yaml)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Split Dataset and Config\n",
        "images = glob.glob(os.path.join(IMAGE_DIR, \"*.tif\"))\n",
        "random.shuffle(images)\n",
        "split = int(len(images) * 0.8)\n",
        "train_imgs = images[:split]\n",
        "val_imgs = images[split:]\n",
        "\n",
        "with open('train.txt', 'w') as f:\n",
        "    f.write('\\n'.join(train_imgs))\n",
        "\n",
        "with open('val.txt', 'w') as f:\n",
        "    f.write('\\n'.join(val_imgs))\n",
        "\n",
        "data_yaml = f\"\"\"\n",
        "names:\n",
        "  0: building\n",
        "path: {os.getcwd()}\n",
        "train: train.txt\n",
        "val: val.txt\n",
        "\"\"\"\n",
        "\n",
        "with open('data.yaml', 'w') as f:\n",
        "    f.write(data_yaml)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Load DIOR Model and Quantize to INT8 with Calibration\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Download DIOR model\n",
        "print(\"Downloading DIOR model from HuggingFace...\")\n",
        "dior_model_path = hf_hub_download(\n",
        "    repo_id=\"pauhidalgoo/yolov8-DIOR\",\n",
        "    filename=\"DIOR_yolov8n_backbone.pt\"\n",
        ")\n",
        "print(f\"Model downloaded to: {dior_model_path}\")\n",
        "\n",
        "# Load the model\n",
        "model = YOLO(dior_model_path)\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# Prepare calibration dataset\n",
        "# Option 1: Use validation images from training (if available)\n",
        "if 'val_imgs' in globals() and len(val_imgs) > 0:\n",
        "    calibration_images = val_imgs[:100]  # Use first 100 validation images\n",
        "    print(f\"Using {len(calibration_images)} validation images for calibration\")\n",
        "# Option 2: Use images from IMAGE_DIR if available\n",
        "elif 'IMAGE_DIR' in globals() and os.path.exists(IMAGE_DIR):\n",
        "    all_images = glob.glob(os.path.join(IMAGE_DIR, \"*.tif\"))\n",
        "    calibration_images = all_images[:100]  # Use first 100 images\n",
        "    print(f\"Using {len(calibration_images)} images from {IMAGE_DIR} for calibration\")\n",
        "# Option 3: Manually specify image paths (uncomment and modify as needed)\n",
        "# calibration_images = [\n",
        "#     \"/path/to/image1.tif\",\n",
        "#     \"/path/to/image2.tif\",\n",
        "#     # ... add more image paths\n",
        "# ]\n",
        "else:\n",
        "    raise ValueError(\"No calibration images found! Please run cells 2-5 first, or manually specify calibration_images list.\")\n",
        "\n",
        "# Export to ONNX first (required for INT8 quantization)\n",
        "print(\"\\nExporting to ONNX format...\")\n",
        "onnx_path = dior_model_path.replace('.pt', '.onnx')\n",
        "model.export(\n",
        "    format='onnx',\n",
        "    imgsz=416,\n",
        "    simplify=True,\n",
        "    opset=12\n",
        ")\n",
        "print(f\"ONNX model exported to: {onnx_path}\")\n",
        "\n",
        "# Now quantize to INT8 with calibration\n",
        "print(\"\\nQuantizing to INT8 with calibration...\")\n",
        "!pip install onnxruntime -q\n",
        "\n",
        "from onnxruntime.quantization import quantize_static, QuantType, CalibrationDataReader\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class DIORCalibrationDataReader(CalibrationDataReader):\n",
        "    \"\"\"Calibration data reader for DIOR model.\"\"\"\n",
        "    def __init__(self, image_paths, image_size=416, input_name=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.image_size = image_size\n",
        "        self.current_index = 0\n",
        "        self.input_name = input_name or 'images'  # Default input name\n",
        "        \n",
        "    def get_next(self):\n",
        "        if self.current_index >= len(self.image_paths):\n",
        "            return None\n",
        "        \n",
        "        image_path = self.image_paths[self.current_index]\n",
        "        self.current_index += 1\n",
        "        \n",
        "        try:\n",
        "            # Load and preprocess image\n",
        "            import rasterio\n",
        "            with rasterio.open(image_path) as src:\n",
        "                img = src.read([1, 2, 3]).transpose(1, 2, 0)\n",
        "                \n",
        "            # Normalize (same as inference)\n",
        "            p2, p98 = np.percentile(img, (2, 98))\n",
        "            img = np.clip((img - p2) / (p98 - p2) * 255.0, 0, 255).astype(np.uint8)\n",
        "            \n",
        "            # Resize to model input size\n",
        "            pil_img = Image.fromarray(img)\n",
        "            pil_img = pil_img.resize((self.image_size, self.image_size))\n",
        "            \n",
        "            # Convert to numpy array and normalize to [0, 1]\n",
        "            img_array = np.array(pil_img).astype(np.float32) / 255.0\n",
        "            \n",
        "            # Convert to CHW format and add batch dimension\n",
        "            img_array = img_array.transpose(2, 0, 1)  # HWC -> CHW\n",
        "            img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "            \n",
        "            return {self.input_name: img_array}\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {image_path}: {e}\")\n",
        "            return self.get_next()  # Skip and try next image\n",
        "\n",
        "# Get the correct input name from ONNX model\n",
        "import onnx\n",
        "onnx_model = onnx.load(onnx_path)\n",
        "input_name = onnx_model.graph.input[0].name\n",
        "print(f\"ONNX model input name: {input_name}\")\n",
        "\n",
        "# Create calibration data reader with correct input name\n",
        "calibration_reader = DIORCalibrationDataReader(calibration_images, image_size=416, input_name=input_name)\n",
        "\n",
        "# Quantize with static calibration\n",
        "int8_model_path = dior_model_path.replace('.pt', '_int8_calibrated.onnx')\n",
        "print(f\"\\nQuantizing model (this may take a few minutes)...\")\n",
        "\n",
        "quantize_static(\n",
        "    model_input=onnx_path,\n",
        "    model_output=int8_model_path,\n",
        "    calibration_data_reader=calibration_reader,\n",
        "    quant_type=QuantType.QInt8,  # Use signed int8 for better accuracy\n",
        "    optimize_model=True\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ… INT8 quantized model saved to: {int8_model_path}\")\n",
        "print(f\"Model size comparison:\")\n",
        "import os\n",
        "original_size = os.path.getsize(onnx_path) / (1024 * 1024)\n",
        "quantized_size = os.path.getsize(int8_model_path) / (1024 * 1024)\n",
        "print(f\"  Original ONNX: {original_size:.2f} MB\")\n",
        "print(f\"  Quantized INT8: {quantized_size:.2f} MB\")\n",
        "print(f\"  Size reduction: {(1 - quantized_size/original_size)*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Zip Results for Download\n",
        "!zip -r trained_model.zip spacenet_rotterdam"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
